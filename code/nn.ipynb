{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\Users\\Hasee\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.1546 - acc: 0.9551     \n",
      "Epoch 2/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0993 - acc: 0.9668     \n",
      "Epoch 3/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0920 - acc: 0.9707     \n",
      "Epoch 4/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0857 - acc: 0.9734     \n",
      "Epoch 5/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0764 - acc: 0.9744     \n",
      "Epoch 6/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0693 - acc: 0.9794     \n",
      "Epoch 7/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0669 - acc: 0.9787     \n",
      "Epoch 8/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0661 - acc: 0.9789     \n",
      "Epoch 9/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0628 - acc: 0.9818     \n",
      "Epoch 10/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0630 - acc: 0.9809     \n",
      "6510/7434 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.1526 - acc: 0.9510     \n",
      "Epoch 2/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.1007 - acc: 0.9681     \n",
      "Epoch 3/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0940 - acc: 0.9707     \n",
      "Epoch 4/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0875 - acc: 0.9740     \n",
      "Epoch 5/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0786 - acc: 0.9758     \n",
      "Epoch 6/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0738 - acc: 0.9781     \n",
      "Epoch 7/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0675 - acc: 0.9802     \n",
      "Epoch 8/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0635 - acc: 0.9814     \n",
      "Epoch 9/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0623 - acc: 0.9812     \n",
      "Epoch 10/10\n",
      "7434/7434 [==============================] - 1s - loss: 0.0601 - acc: 0.9829     \n",
      "6990/7434 [===========================>..] - ETA: 0sResults: 98.49% (0.15%)\n",
      "TP is 6217\n",
      "FP is 7717\n",
      "TN is 155\n",
      "FN is 779\n",
      "accuracy:   0.5233393177737882\n",
      "precision:   0.4461748241710923\n",
      "f1:   0.5940754897276637\n",
      "recall:   0.8886506575185821\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "os.chdir('C:\\\\Users\\\\Hasee\\\\Desktop\\\\ab')\n",
    "\n",
    "seed =123\n",
    "# Load remaining libraries\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed = 123\n",
    "# Read in data\n",
    "train = pd.read_csv(\"train.csv\", sep=\",\",)\n",
    "test = pd.read_csv('test.csv',sep = ',')\n",
    "\n",
    "# Get number of features\n",
    "num_cols = train.shape[1]-1\n",
    "\n",
    "# Split out features and labels\n",
    "train_x = train.values[:, 1:].astype(float)\n",
    "train_y = train.values[:, 0].astype(int)\n",
    "test_x = test.values[:, 1:].astype(float)\n",
    "test_y = test.values[:, 0].astype(int)\n",
    "train_x = preprocessing.scale(train_x)\n",
    "test_x = preprocessing.scale(test_x)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_Y = encoder.transform(train_y)\n",
    "\n",
    "\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=50, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(36, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, nb_epoch=5, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, train_x, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "final_model = create_baseline()\n",
    "predict_y = final_model.predict(train_x)\n",
    "\n",
    "\n",
    "#by setting probability boundary and adjust probability as time goes,\n",
    "#we could be able to adjust model parametre to reach a better performance\n",
    "def set_p(x,prob=0.50000):\n",
    "    predict_num = []\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i]>prob:\n",
    "            predict_num.append(1)\n",
    "        else:\n",
    "            predict_num.append(0)\n",
    "    return predict_num\n",
    "prediction = set_p(predict_y)    \n",
    "truth_list = train_y.tolist()\n",
    "results = pd.DataFrame(\n",
    "        {\"Prediction\": prediction,\n",
    "         \"Truth\": truth_list\n",
    "         })\n",
    "\n",
    "\n",
    "def count_confusion(x):\n",
    "    #this function calacuates the comfusion metrics \n",
    "    #and provide model performance evaluation\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[\"Truth\"].values[i] == 1 and x[\"Prediction\"].values[i] == 1:\n",
    "            TP+=1\n",
    "        if x[\"Truth\"].values[i] == 0 and x[\"Prediction\"].values[i] == 1:\n",
    "            FP+=1   \n",
    "        if x[\"Truth\"].values[i] == 1 and x[\"Prediction\"].values[i] == 0:\n",
    "            TN += 1\n",
    "        if x[\"Truth\"].values[i] == 0 and x[\"Prediction\"].values[i] == 0:\n",
    "            FN += 1\n",
    "    \n",
    "    print('TP is '+str(TP))\n",
    "    print('FP is '+str(FP))\n",
    "    print('TN is '+str(TN))\n",
    "    print('FN is '+str(FN))\n",
    "    recall = TP/(TP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    print(\"accuracy:  \", (TP+FN)/(TP+TN+FN+TP))\n",
    "    print(\"precision:  \", precision)\n",
    "    print(\"f1:  \", 2 * precision*recall/(precision+recall))\n",
    "    print(\"recall:  \", recall)\n",
    "count_confusion(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
