{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xujialu/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x [[-0.7093087  -0.69260166 -0.69260166 ...,  0.         -0.6596083\n",
      "  -1.44849143]\n",
      " [-0.7093087  -0.69260166 -0.69260166 ...,  0.         -0.6596083\n",
      "   1.24900837]\n",
      " [-0.7093087  -0.69260166 -0.69260166 ...,  0.         -0.6596083\n",
      "  -0.77411648]\n",
      " ..., \n",
      " [ 2.00755601  1.02596536  1.02596536 ...,  0.          1.6056429\n",
      "  -1.11809574]\n",
      " [ 2.04336868  0.9061057   0.9061057  ...,  0.          1.4732043\n",
      "  -1.02983096]\n",
      " [ 0.76617226  0.79797901  0.79797901 ...,  0.          1.38365753\n",
      "  -0.44291603]]\n",
      "train_x [[-0.05332252 -0.0464695  -0.0464695  ..., -0.004557   -0.22054262\n",
      "  -1.11935411]\n",
      " [-0.05332252 -0.0464695  -0.0464695  ..., -0.004557   -0.22054262\n",
      "  -1.11935411]\n",
      " [-0.05332252 -0.0464695  -0.0464695  ..., -0.004557   -0.22054262\n",
      "  -0.51591414]\n",
      " ..., \n",
      " [-0.05332252 -0.0464695  -0.0464695  ..., -0.004557   -0.22054262\n",
      "  -1.11935411]\n",
      " [-0.05332252 -0.0464695  -0.0464695  ..., -0.004557   -0.22054262\n",
      "  -0.51591414]\n",
      " [-0.05332252 -0.0464695  -0.0464695  ..., -0.004557    2.3831471\n",
      "  -1.11935411]]\n",
      "start running\n",
      "scores [ 0.9394958   0.97209146  0.97712748  0.97981837  0.98351833]\n",
      "train\n",
      "TP is5956\n",
      "FP is416\n",
      "TN is11\n",
      "FN is8485\n",
      "accuracy 0.7076146609172873\n",
      "precision 0.9347143753923415\n",
      "f1 0.5723345985682026\n",
      "recall 0.4124368118551347\n",
      "test\n",
      "TP is6350\n",
      "FP is22\n",
      "TN is8450\n",
      "FN is46\n",
      "accuracy 0.3017550481222872\n",
      "precision 0.9965473948524796\n",
      "f1 0.994674185463659\n",
      "recall 0.9928080050031269\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/Users/xujialu/Desktop/Data_50/data_new_balanced.csv\", sep=\",\",)# the balanced dataset\n",
    "test = pd.read_csv(\"/Users/xujialu/Desktop/Data_50/data_new_imbalanced.csv\",sep = ',')   # the imbalanced dataset\n",
    "#train = pd.read_csv(\"/Users/xujialu/Desktop/Data_50/data_new_imbalanced.csv\",sep = ',')   # the imbalanced dataset\n",
    "#test = pd.read_csv(\"/Users/xujialu/Desktop/Data_50/data_new_balanced.csv\", sep=\",\",)# the balanced dataset\n",
    "\n",
    "\n",
    "#load dataset\n",
    "train_x = train.values[:,1:]\n",
    "train_x = preprocessing.scale(train_x)\n",
    "print(\"train_x\",train_x)\n",
    "train_y = train['y']\n",
    "test_x  = test.values[:,1:]\n",
    "test_x = preprocessing.scale(test_x)\n",
    "print(\"train_x\",test_x)\n",
    "test_y  = train['y']\n",
    "\n",
    "#train the SVM model\n",
    "clf = svm.SVC()\n",
    "clf = svm.SVC(kernel='poly', C=1).fit(train_x, train_y)\n",
    "print('start running')\n",
    "\n",
    "#save the SVM model\n",
    "s = joblib.dump(clf, 'filename1.pkl')\n",
    "#load the SVM model\n",
    "clf2 = joblib.load('filename1.pkl')\n",
    "\n",
    "# cross-validation \n",
    "scores = cross_val_score(clf2, train_x,train_y, cv=5)\n",
    "print(\"scores\",scores)\n",
    "\n",
    "#evalutation accuracy, precision, recall, F1\n",
    "def count_confusion(x,y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        if y[i] == 1 and x.values[i] == 1:\n",
    "            TP += 1\n",
    "        if y[i] == 0 and x.values[i] == 1:\n",
    "            FP += 1\n",
    "        if y[i] == 1 and x.values[i] == 0:\n",
    "            TN += 1\n",
    "        if y[i] == 0 and x.values[i] == 0:\n",
    "            FN += 1\n",
    "    print('TP is' + str(TP))\n",
    "    print('FP is' + str(FP))\n",
    "    print('TN is' + str(TN))\n",
    "    print('FN is' + str(FN))\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    print(\"accuracy\", (TP + FN) / (TP + TN + FN + TP))\n",
    "    print(\"precision\", precision)\n",
    "    print(\"f1\", 2 * precision * recall / (precision + recall))\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "\n",
    "#test the SVM with trainset and testset\n",
    "predict1=clf2.predict(train_x)\n",
    "predict2=clf2.predict(test_x)\n",
    "print(\"train\")\n",
    "count_confusion(train_y,predict1)\n",
    "print(\"test\")\n",
    "count_confusion(test_y,predict2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
